{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "common-federal",
   "metadata": {},
   "source": [
    "### Section 1: Data extraction from Convokit's switchboard corpus\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greek-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "from convokit import Corpus, download\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "traditional-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty printing of cells within the Colab version of this notebook\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "color-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Globals\n",
    "\n",
    "corpus_name = \"switchboard-corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precise-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/muhammadumair/.convokit/downloads/switchboard-corpus\n"
     ]
    }
   ],
   "source": [
    "swbc = Corpus(filename=download(corpus_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "joint-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 440\n",
      "Number of Utterances: 122646\n",
      "Number of Conversations: 1155\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Each conversation has three components: Conversations, Utterances, and Speakers\n",
    "# Each component has: Primary data fields / Metadata\n",
    "print(swbc.print_summary_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "magnetic-single",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Extract all the utterances and tags in the conversations and store as a local CSV file\n",
    "\n",
    "# Collect a list of all of dataframes representing all utterances in every conversation. \n",
    "conv_utt_dataframes = list()\n",
    "conversation_ids = swbc.get_conversation_ids()\n",
    "for id_ in conversation_ids:\n",
    "    conv = swbc.get_conversation(id_)\n",
    "    conv_utt_dataframes.append(conv.get_utterances_dataframe())\n",
    "\n",
    "# For all utterances in every conversation, extract required values and save them as dataframes.\n",
    "conversation_dfs = list()\n",
    "for conv_utt_df in conv_utt_dataframes:\n",
    "    data = {\n",
    "        #\"speakers\" : list(),\n",
    "        \"tags\" : list(),\n",
    "        \"utterances\" : list()}\n",
    "    \n",
    "    conv_utt_df = conv_utt_df[[\"speaker\",\"meta.tag\"]]\n",
    "    for index, utt in conv_utt_df.iterrows():\n",
    "        speaker = utt[\"speaker\"]\n",
    "        tagged_utts = utt[\"meta.tag\"]\n",
    "        for utterance in tagged_utts:\n",
    "            #data[\"speakers\"].append(speaker)\n",
    "            data[\"utterances\"].append(utterance[0])\n",
    "            data[\"tags\"].append(utterance[1])\n",
    "        \n",
    "    conversation_dfs.append(pd.DataFrame(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ongoing-territory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cleaning up the utterances to remove all non-alphabetical characters. \n",
    "for i in range(len(conversation_dfs)):    \n",
    "    df = conversation_dfs[i]\n",
    "    for j in range(len(df[\"utterances\"])):\n",
    "        utterance = df.at[j,'utterances'].split()\n",
    "        for k in range(len(utterance)):\n",
    "            utterance[k] = \"\".join([c for c in utterance[k] if c.isalpha()])\n",
    "        utterance = \" \".join([word for word in utterance if word])\n",
    "        df.at[j,'utterances'] = utterance\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspended-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replacing all non-supported tags with NOISE tags. \n",
    "supported_tags = (\"sd\",\"b\",\"sv\", \"aa\", \"%\", \"ba\",\"qy\",\"x\",\"ny\",\"fc\",\"qw\",\"nn\",\"bk\",\"h\",\"qy^d\",\"fo_o_fw_by_bc\",\n",
    "                 \"bh\", \"^q\",\"bf\",\"na\",\"ad\",\"^2\",\"b^m\",\"qo\",\"qh\",\"^h\",\"ar\",\"ng\",\"bt\",\"no\",\"fp\",\"qrr\",\"arp_nd\",\n",
    "                 \"t3\",\"oo_co_cc\",\"t1\",\"bd\",\"aap_am\",\"^g\",\"qw^d\",\"fa\",\"ft\")\n",
    "noise_tag = \"noise\"\n",
    "for i in range(len(conversation_dfs)):    \n",
    "    df = conversation_dfs[i]\n",
    "    for j in range(len(df[\"tags\"])):\n",
    "        tag = df.at[j,'tags']\n",
    "        df.at[j,'tags'] = tag if tag in supported_tags else noise_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "renewable-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving all files to the output directory. \n",
    "\n",
    "# NOTE: Path changes per user\n",
    "output_dir_path = \"/Users/muhammadumair/Documents/Repositories/mumair01-Repos/repair-tagging/data\"\n",
    "    \n",
    "for df, conv_utt_df in zip(conversation_dfs,conv_utt_dataframes):\n",
    "    file_path = \"{}/{}.csv\".format(output_dir_path,conv_utt_df[\"conversation_id\"][0])  \n",
    "    df.to_csv(file_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-plasma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
